% !TEX root = manuscript.tex
\glsresetall
%\addbibresource{../resource/ref.bib}

\chapter{Conclusions}% and Future Perspectives}
\label{chp:conclusion}

As presented in Chapter \ref{chp:introduction}, the main purposes of this work was to study \gls{rl} solutions applied to \gls{la}, while also giving an overview of the \gls{phy} and transmission procedures associated with it.

Therewith, Chapter \ref{chp:theory} presented some fundamentals of \gls{rl} and of the Q-Learning.
%
It also presented the transmission process for downlink data and the procedure from \gls{phy} perspective, giving an overview of the main steps of the transmission chain.

Regarding the proposed solutions and their performance evaluations, on one hand, Chapter \ref{chp:amc} presented our solution based on a Q-Learning algorithm with a specially defined \gls{cqi} and showed the gain in spectral efficiency when compared to the baseline solutions, \gls{illa} and \gls{olla}.
%
On the other hand, Chapter \ref{chp:la} presented our solution that chooses the \gls{mcs} and the \gls{pmi}, becoming an \gls{amc} solution and a rank adaptation solution. The performance evaluations showed that the proposed solution achieves a performance close to that of a brute force solution that searchs for the precoder that maximizes the \gls{sinr}.

As a perspective of this work, we highlight the extension of the proposed \gls{rl}-based framework to include all the precoders of the standard \cite{3gpp.38.214} and the evaluation of a single \gls{rl} agent choosing both the \gls{mcs} and the \gls{pmi}.
%
Moreover, a comparison with other \gls{rl}-based algorithms such as multi-armed bandits (MABs) \cite{zhou2015survey} or deep RL solutions \cite{DeepRLSurvey} is envisioned.

In addition, since \gls{nr} is a beam-based system, including the beam domain is another perspective.
%
In other words, our \gls{rl}-based solutions can also incorporate the selection of the best beam to transmit/receive data, among a set of choices (codebook).
